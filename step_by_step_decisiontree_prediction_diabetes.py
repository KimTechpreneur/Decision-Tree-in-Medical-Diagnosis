# -*- coding: utf-8 -*-
"""Step by step Decisiontree prediction diabetes

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bls2C6agrzBVRk4DZ8j_RkcVP3IStB6Q

**Install & Importing Libraries**
"""

import os

# Install necessary libraries
!pip install graphviz

# Import libraries
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.preprocessing import OneHotEncoder
import graphviz
from google.colab import files
import matplotlib.pyplot as plt

"""**Data Loading and Preprocessing**"""



# Check if the dataset file already exists in the current directory
file_name = 'diabetes_prediction_dataset.csv'
if os.path.exists(file_name):
    # Load data from the file
    data = pd.read_csv(file_name)
    print("Data loaded successfully.")
else:
    # Prompt the user to upload the file
    print(f"File '{file_name}' not found in the current directory. Please upload the file.")
    uploaded = files.upload()
    data = pd.read_csv(file_name)  # Assuming the user uploads the correct file

"""**Feature Encoding**"""

# Display the first few rows of the dataset
print(data.head())

# Define features and target variable
FEATURES = ['age', 'gender', 'bmi', 'hypertension', 'heart_disease', 'smoking_history', 'HbA1c_level', 'blood_glucose_level']
TARGET = 'diabetes'

# Encode categorical features
encoder = OneHotEncoder(sparse=False)
encoded_features = pd.DataFrame(encoder.fit_transform(data),
                                columns=encoder.get_feature_names_out())

# Drop the original categorical features and concatenate the encoded features
data = pd.concat([data.drop(FEATURES, axis=1), encoded_features], axis=1)

"""**Data Splitting**"""

# Split the data into training and testing sets
X = data.drop(TARGET, axis=1)
y = data[TARGET]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""**Model Training**"""

from sklearn.tree import DecisionTreeClassifier

# Train the model
clf = DecisionTreeClassifier(random_state=42)
clf.fit(X_train, y_train)

"""**Model Evaluation**"""

from sklearn.metrics import accuracy_score, classification_report

# Evaluate the model
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f'Accuracy: {accuracy}')
print('Classification Report:')
print(report)

"""**Decision Tree Visualization**"""

from sklearn.tree import export_graphviz
import graphviz

# Visualize the decision tree
dot_data = export_graphviz(clf, out_file=None,
                           feature_names=X.columns,
                           class_names=['Negative', 'Positive'],
                           filled=True, rounded=True,
                           special_characters=True)
graph = graphviz.Source(dot_data)
graph.render("diabetes_decision_tree")

"""**Interactive Prediction**"""

import ipywidgets as widgets
from IPython.display import display

# Function to take user input and make predictions using widgets
def predict_diabetes_widget(age, gender, bmi, hypertension, heart_disease, smoking_history, HbA1c_level, blood_glucose_level):
    # Create DataFrame for input features
    input_data = pd.DataFrame({
        'age': [age],
        'bmi': [bmi],
        'hypertension': [hypertension],
        'heart_disease': [heart_disease],
        'HbA1c_level': [HbA1c_level],
        'blood_glucose_level': [blood_glucose_level],
        'gender_Female': [1 if gender == 'Female' else 0],
        'gender_Male': [1 if gender == 'Male' else 0],
        'smoking_history_never': [1 if smoking_history == 'never' else 0],
        'smoking_history_current': [1 if smoking_history == 'current' else 0],
        'smoking_history_ex': [1 if smoking_history == 'ex' else 0],
        'smoking_history_currently': [1 if smoking_history == 'currently' else 0],
        'smoking_history_No Info': [1 if smoking_history == 'No Info' else 0],
    })

    # Ensure all feature names are present in input_data and in correct order
    feature_names = X.columns
    for feature in feature_names:
        if feature not in input_data.columns:
            input_data[feature] = 0

    # Reorder columns to match the training set
    input_data = input_data[feature_names]

    # Predict
    prediction = clf.predict(input_data)
    result = 'Positive' if prediction[0] == 1 else 'Negative'
    print(f"Diabetes Prediction: {result}")

# Create widgets for input
age = widgets.FloatText(description="Age:")
gender = widgets.Dropdown(options=['Male', 'Female'], description="Gender:")
bmi = widgets.FloatText(description="BMI:")
hypertension = widgets.Dropdown(options=[0, 1], description="Hypertension:")
heart_disease = widgets.Dropdown(options=[0, 1], description="Heart Disease:")
smoking_history = widgets.Dropdown(options=['never', 'current', 'ex', 'currently', 'No Info'], description="Smoking History:")
HbA1c_level = widgets.FloatText(description="HbA1c Level:")
blood_glucose_level = widgets.FloatText(description="Blood Glucose Level:")
button = widgets.Button(description="Predict")

# Display widgets
display(age, gender, bmi, hypertension, heart_disease, smoking_history, HbA1c_level, blood_glucose_level, button)

# Set up button click event
def on_button_click(b):
    predict_diabetes_widget(age.value, gender.value, bmi.value, hypertension.value, heart_disease.value, smoking_history.value, HbA1c_level.value, blood_glucose_level.value)

button.on_click(on_button_click)

"""**Explanation:**
The classification report provides several key metrics for evaluating the performance of the model:

**Precision:** The proportion of true positive predictions among all positive predictions. For class 0 (non-diabetic), the precision is 0.98, indicating that 98% of the positive predictions are correct. For class 1 (diabetic), the precision is 0.71.

**Recall** The proportion of true positive predictions among all actual positives. For class 0, the recall is 0.97, meaning 97% of actual non-diabetic cases are correctly identified. For class 1, the recall is 0.74.

**F1-score:** The harmonic mean of precision and recall, providing a balance between the two. For class 0, the F1-score is 0.97, while for class 1, it is 0.72.

**Support:** The number of actual occurrences of each class in the test set. There are 27,453 instances of class 0 and 2,547 instances of class 1.

**Accuracy:** The overall proportion of correct predictions. The accuracy of the model is 0.9524, meaning the model correctly predicts diabetes status for 95.24% of the test cases.
Macro average: The unweighted mean of the precision, recall, and F1-score for each class, treating all classes equally.

**Weighted average:** The weighted mean of the precision, recall, and F1-score, accounting for the number of instances in each class.

***Interpretation:***
The high precision and recall for class 0 indicate that the model is very effective at identifying non-diabetic individuals.
The lower precision and recall for class 1 suggest that the model has some difficulty correctly identifying diabetic individuals, which could be due to class imbalance or inherent complexity in distinguishing these cases.


"""